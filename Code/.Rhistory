all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data$Y)
}
# Some predictions are NA's for whatever reason, thus we make them 0
all_predictions[is.na(all_predictions)] <- 0
# Calculating roc curve
pred <- prediction(all_predictions, all_actuals)
perf <- performance(pred, "tpr", "fpr")
any(is.na(all_actuals))
# As before, we clear the holding variables
all_predictions <- c()
all_actuals <- c()
# Time-series cross-validation for 5 folds with the same fold_size as before
k <- 5
fold_size <- floor(nrow(df_Altman) / k)
# Loop
for (i in 1:k) {
# Définir les indices pour le training et le test
train_indices <- 1:(i * fold_size - fold_size)
test_indices <- (i * fold_size - fold_size + 1):(i * fold_size)
train_data <- df_Altman[train_indices, ]
test_data <- df_Altman[test_indices, ]
transformed_Altman_model <- glm(
Y ~ RETA_transformed + EBTA_transformed + ME_BL_transformed + Size + Age,
data = df_Altman,
family = binomial(link = "logit")
)
# Prediction on test data
predictions <- predict(transformed_Altman_model, newdata = test_data, type = "response")
# results stored
all_predictions <- c(all_predictions, predictions)
all_actuals <- c(all_actuals, test_data$Y)
}
# Some predictions are NA's for whatever reason, thus we make them 0
# all_predictions[is.na(all_predictions)] <- 0
# Calculating roc curve
pred <- prediction(all_predictions, all_actuals)
perf <- performance(pred, "tpr", "fpr")
plot(perf,
avg="threshold",
spread.estimate="boxplot",
lwd= 3,
main= "5 Fold Cross Validation Altman Model")
# Calculate AUC
auc <- performance(pred, "auc")
auc_value <- as.numeric(auc@y.values)
cat("Area Under the ROC Curve (AUC):", auc_value, "\n")
# We calculate average return
df_DtD <- df %>%
arrange(gvkey, fyear) %>%
group_by(gvkey) %>%
mutate(
r_prev = (avg_market_cap - lag(avg_market_cap)) / lag(avg_market_cap)
) %>%
ungroup()
head(df_DtD, 10)
attach(df_DtD)
# we need the Variables: E (Market Value of Equity), sigma_E (Equity Volatility), F (Face Value of Debt), r_prev (Previous year's return)
df_DtD <- df_DtD %>%
mutate(
# Step 2: Approximate debt volatility using a linear combination as in the article
sigma_D = 0.05 + 0.25 * rolling_volatility,  # Debt volatility
# Step 3: Calculate total firm volatility
sigma_V = (avg_market_cap / (avg_market_cap + lt)) * rolling_volatility + (lt / (avg_market_cap + lt)) * sigma_D,  # Total volatility
# Step 4: Set expected return
mu = r_prev,  # Expected return based on past equity returns
# Step 5: Calculate Naive DtD
DtD_naive = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * sigma_V^2) * 1) / (sigma_V * sqrt(1))
)
# Step 6: Iterative Merton DtD (using simplified assumptions for demonstration)
df_DtD <- df_DtD %>%
mutate(
DtD_modeled = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * rolling_volatility^2) * 1) / (rolling_volatility * sqrt(1))  # Using equity volatility directly
)
df_DtD <- df_DtD %>%
mutate(
P_default_naive = pnorm(-DtD_naive),
P_default_modeled = pnorm(-DtD_modeled)
)
# Step 7: Calculate probabilities of default
P_default_naive = pnorm(-DtD_naive)  # Probability of default based on DtD_naive
View(df_DtD)
detach(df_DtD)
# attach(df_DtD)
# we need the Variables: E (Market Value of Equity), sigma_E (Equity Volatility), F (Face Value of Debt), r_prev (Previous year's return)
df_DtD <- df_DtD %>%
mutate(
# Step 2: Approximate debt volatility using a linear combination as in the article
sigma_D = 0.05 + 0.25 * rolling_volatility,  # Debt volatility
# Step 3: Calculate total firm volatility
sigma_V = (avg_market_cap / (avg_market_cap + lt)) * rolling_volatility + (lt / (avg_market_cap + lt)) * sigma_D,  # Total volatility
# Step 4: Set expected return
mu = r_prev,  # Expected return based on past equity returns
# Step 5: Calculate Naive DtD
DtD_naive = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * sigma_V^2) * 1) / (sigma_V * sqrt(1))
)
# Step 6: Iterative Merton DtD (using simplified assumptions for demonstration)
df_DtD <- df_DtD %>%
mutate(
DtD_modeled = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * rolling_volatility^2) * 1) / (rolling_volatility * sqrt(1))  # Using equity volatility directly
)
df_DtD <- df_DtD %>%
mutate(
P_default_naive = pnorm(-DtD_naive),
P_default_modeled = pnorm(-DtD_modeled)
)
# Step 7: Calculate probabilities of default
P_default_naive = pnorm(-DtD_naive)  # Probability of default based on DtD_naive
# attach(df_DtD)
# we need the Variables: E (Market Value of Equity), sigma_E (Equity Volatility), F (Face Value of Debt), r_prev (Previous year's return)
df_DtD <- df_DtD %>%
mutate(
# Step 2: Approximate debt volatility using a linear combination as in the article
sigma_D = 0.05 + 0.25 * rolling_volatility,  # Debt volatility
# Step 3: Calculate total firm volatility
sigma_V = (avg_market_cap / (avg_market_cap + lt)) * rolling_volatility + (lt / (avg_market_cap + lt)) * sigma_D,  # Total volatility
# Step 4: Set expected return
mu = r_prev,  # Expected return based on past equity returns
# Step 5: Calculate Naive DtD
DtD_naive = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * sigma_V^2) * 1) / (sigma_V * sqrt(1))
)
# Step 6: Iterative Merton DtD (using simplified assumptions for demonstration)
df_DtD <- df_DtD %>%
mutate(
DtD_modeled = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * rolling_volatility^2) * 1) / (rolling_volatility * sqrt(1))  # Using equity volatility directly
)
# Calculate probabilities of default
df_DtD <- df_DtD %>%
mutate(
P_default_naive = pnorm(-DtD_naive),
P_default_modeled = pnorm(-DtD_modeled)
)
# Compare the two predictors
comparison <- df_DtD %>%
select(conm, fyear, DtD_naive, DtD_modeled, P_default_naive, P_default_modeled)
comparison_cleaned <- na.omit(comparison)
# Output the comparison
head(comparison_cleaned)
#cleaning data
comparison_cleaned <- comparison %>%
filter(!is.na(DtD_naive), !is.na(DtD_modeled))
# Calcul de la différence entre les deux DtD
comparison_cleaned <- comparison_cleaned %>%
mutate(DtD_difference = DtD_modeled - DtD_naive)
detach(df_DtD)
# attach(df_DtD)
# we need the Variables: E (Market Value of Equity), sigma_E (Equity Volatility), F (Face Value of Debt), r_prev (Previous year's return)
df_DtD <- df_DtD %>%
mutate(
# Step 2: Approximate debt volatility using a linear combination as in the article
sigma_D = 0.05 + 0.25 * rolling_volatility,  # Debt volatility
# Step 3: Calculate total firm volatility
sigma_V = (avg_market_cap / (avg_market_cap + lt)) * rolling_volatility + (lt / (avg_market_cap + lt)) * sigma_D,  # Total volatility
# Step 4: Set expected return
mu = r_prev,  # Expected return based on past equity returns
# Step 5: Calculate Naive DtD
DtD_naive = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * sigma_V^2) * 1) / (sigma_V * sqrt(1))
)
# Step 6: Iterative Merton DtD (using simplified assumptions for demonstration)
df_DtD <- df_DtD %>%
mutate(
DtD_modeled = (log((avg_market_cap + lt) / lt) + (r_prev - 0.5 * rolling_volatility^2) * 1) / (rolling_volatility * sqrt(1))  # Using equity volatility directly
)
# Calculate probabilities of default
df_DtD <- df_DtD %>%
mutate(
P_default_naive = pnorm(-DtD_naive),
P_default_modeled = pnorm(-DtD_modeled)
)
# Compare the two predictors
comparison <- df_DtD %>%
select(conm, fyear, DtD_naive, DtD_modeled, P_default_naive, P_default_modeled)
comparison_cleaned <- na.omit(comparison)
# Output the comparison
head(comparison_cleaned)
#cleaning data
comparison_cleaned <- comparison %>%
filter(!is.na(DtD_naive), !is.na(DtD_modeled))
# Calcul de la différence entre les deux DtD
comparison_cleaned <- comparison_cleaned %>%
mutate(DtD_difference = DtD_modeled - DtD_naive)
attach(df_DtD)
#function for normal cumulative distribution
N <- function(x) {
pnorm(x)
}
# fonction use to derive d1
calc_d1 <- function(V, lt, r, sigma_V, T) {
(log(V / lt) + (r + 0.5 * sigma_V^2) * T) / (sigma_V * sqrt(T))
}
# Iteration process to estimate V and sigma V
estimate_V_sigmaV <- function(avg_market_cap, rolling_volatility, lt, r = 0.04, T = 1, tol = 1e-6, max_iter = 100) {
# Initialisation
V <- avg_market_cap + lt
sigma_V <- rolling_volatility * avg_market_cap / (avg_market_cap + lt)
# Itération
for (i in 1:max_iter) {
# Calcul de d1 et d2
d1 <- calc_d1(V, lt, r, sigma_V, T)
d2 <- d1 - sigma_V * sqrt(T)
# Updating V and sigma V
V_new <- avg_market_cap + lt * exp(-r * T) * N(d2) / N(d1)
sigma_V_new <- (rolling_volatility * avg_market_cap) / (V_new * N(d1))
# convergence
if (abs(V_new - V) < tol && abs(sigma_V_new - sigma_V) < tol) {
break
}
# Updatign for next itération
V <- V_new
sigma_V <- sigma_V_new
}
list(V = V, sigma_V = sigma_V, iterations = i)
}
#calculate the DtD and the PD
# Calcul de la Distance to Default (DtD)
calc_DtD <- function(V, lt, r, sigma_V, T) {
(log(V / lt) + (r - 0.5 * sigma_V^2) * T) / (sigma_V * sqrt(T))
}
# Calcul de la probabilité de défaut
calc_default_probability <- function(DtD) {
pnorm(-DtD)
}
# Calculer DtD
DtD <- calc_DtD(V = V_est, lt = lt, r = r, sigma_V = sigma_V_est, T = T)
# Overview
table(df$Y)
# To improve model performance we winzorise our data
df_winzorised <- df |>
select(is.numeric()) |>
mutate(across(everything(), ~ DescTools::Winsorize(.x , quantile( .x, probs = c(0.00, 0.975)))))
# Overview
table(df$Y)
# To improve model performance we winzorise our data
df_winzorised <- df |>
select(is.numeric(df)) |>
mutate(across(everything(), ~ DescTools::Winsorize(.x , quantile( .x, probs = c(0.00, 0.975)))))
is.numeric(df)
is.numeric(df[df])
df[is.numeric(df)]
df
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
Winsorize(x, probs = c(0.025, 0.975), na.rm = TRUE)
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x, probs = c(0.025, 0.975), na.rm = TRUE)
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x, quantile = c(0.025, 0.975), na.rm = TRUE)
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x, quantiles = c(0.025, 0.975), na.rm = TRUE)
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x, quantiles = (x, probs=c(0.025, 0.975)), na.rm = TRUE)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x, quantile = (x, probs=c(0.025, 0.975)), na.rm = TRUE)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(.x , quantile( .x, probs = c(0.00, 0.975)), na.rm = TRUE)
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(.x , quantile( .x, probs = c(0.00, 0.975)))
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.00, 0.975)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.025, 0.975)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.025, 0.975)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.025, 0.999)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.025, 0.99)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.05, 0.999)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.999)))
})
table(df_winsorized$Y)
df <- readRDS('../data/df.rds')
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.999)))
})
# Overview
table(df$Y)
df_winsorized <- df  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.999)), na.rm = TRUE)
})
library(tidyverse)
library(scales)
library(RSQLite)
library(dbplyr)
library(RPostgres)
library(randomForest)
library(glmnet)
library(ROCR)
library(dplyr)
library(tidyr)
# Loading data
df <- readRDS('../data/df.rds')
# Correction for -inf in the df for all columns # df$WCTA[is.infinite(df$WCTA)] <- NA applied on all numerical columns
df <- data.frame(lapply(df, function(col){
if (is.numeric(col)) {
col[is.infinite(col)] <- NA
}
return(col)
}))
# We replace NA's with the mean
df <- data.frame(lapply(df, function(col) {
if (is.numeric(col)) {
col[is.na(col)] <- mean(col, na.rm = TRUE)  # Replace NA with column mean
}
return(col)
}))
# Overview
table(df$Y)
df_winsorized <- df[]  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.999)))
})
table(df_winsorized$Y)
# Overview
table(df$Y)
df_winsorized <- df[]  # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.975)))
})
table(df_winsorized$Y)
df_winsorized <- df # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
numeric_columns <- numeric_columns |> select(-Y)
# Overview
table(df$Y)
df_winsorized <- df # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized, is.numeric)  # Identify numeric columns
numeric_columns <- numeric_columns |> filter(-Y)
numeric_columns
numeric_columns <- numeric_columns[Y == FALSE]
numeric_columns
numeric_columns <- sapply(df_winsorized |> select(-Y), is.numeric)
numeric_columns
# Overview
table(df$Y)
df_winsorized <- df # Create a copy to store the winsorized dataframe
# Apply Winsorize to each numeric column
numeric_columns <- sapply(df_winsorized |> select(-Y), is.numeric)  # Identify numeric columns
df_winsorized[, numeric_columns] <- lapply(df_winsorized[, numeric_columns], function(x) {
DescTools::Winsorize(x , quantile(x, probs = c(0.1, 0.975)))
})
table(df_winsorized$Y)
df_winsorized
# Overview
table(df$Y)
library(tidyverse)
library(scales)
library(RSQLite)
library(dbplyr)
library(RPostgres)
library(randomForest)
library(glmnet)
library(ROCR)
library(dplyr)
library(tidyr)
library(pROC)
library(caret)
# Loading data
df <- readRDS('../data/df.rds')
# Correction for -inf in the df for all columns # df$WCTA[is.infinite(df$WCTA)] <- NA applied on all numerical columns
df <- data.frame(lapply(df, function(col){
if (is.numeric(col)) {
col[is.infinite(col)] <- NA
}
return(col)
}))
# We replace NA's with the mean
df <- data.frame(lapply(df, function(col) {
if (is.numeric(col)) {
col[is.na(col)] <- mean(col, na.rm = TRUE)  # Replace NA with column mean
}
return(col)
}))
table(df$Y)
# For this part of the code, we need additional packages
library(rsample)
train_index_df <- sample(1:nrow(df), size = 0.05 * nrow(df))
train_temp_df <- df[train_index_df, ]
# test_temp_df <- df[-train_index_df, ]
df_ordered <- train_temp_df[order(train_temp_df$fyear), ]
all_predictions <- c()
all_actuals <- c()
time_series_splits <- rolling_origin(
df_ordered,
initial = 5 * 12,   # Use the first 5 years (assuming yearly data, adjust if needed)
assess = 1 * 12,    # Use 1 year as the test set
cumulative = TRUE   # Allow the training set to grow with each fold
)
print(time_series_splits)
# For this part of the code, we need additional packages
library(rsample)
train_index_df <- sample(1:nrow(df), size = 0.05 * nrow(df))
train_temp_df <- df[train_index_df, ]
# test_temp_df <- df[-train_index_df, ]
df_ordered <- train_temp_df[order(train_temp_df$fyear), ]
all_predictions <- c()
all_actuals <- c()
time_series_splits <- rolling_origin(
df_ordered,
initial = 5 * 12,   # Use the first 5 years (assuming yearly data, adjust if needed)
assess = 1 * 12,    # Use 1 year as the test set
cumulative = TRUE   # Allow the training set to grow with each fold
)
print(time_series_splits)
